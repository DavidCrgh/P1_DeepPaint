{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Library imports\r\n",
    "import random\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch import nn, optim\r\n",
    "from torchvision import datasets\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.models.resnet import resnet18\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "from fastai.vision.learner import create_body\r\n",
    "from fastai.vision.models.unet import DynamicUnet\r\n",
    "\r\n",
    "from ignite.engine import Events, Engine, create_supervised_trainer, create_supervised_evaluator\r\n",
    "from ignite.metrics import Accuracy, Loss, PSNR, SSIM, FID\r\n",
    "\r\n",
    "from skimage.color import rgb2lab, lab2rgb\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Hyperparameters\r\n",
    "NET_IMG_SIZE = 256\r\n",
    "LEARNING_RATE = 1e-3\r\n",
    "BATCH_SIZE = 16"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def rgbfromlab(L, ab):\r\n",
    "    L = (L + 1.) * 50.\r\n",
    "    ab = ab * 110.\r\n",
    "    \r\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\r\n",
    "    rgb_imgs = []\r\n",
    "    for img in Lab:\r\n",
    "        img_rgb = lab2rgb(img)\r\n",
    "        rgb_imgs.append(img_rgb)\r\n",
    "    return np.stack(rgb_imgs, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class VOCColorization(datasets.VOCDetection):\r\n",
    "    def __init__(\r\n",
    "        self, \r\n",
    "        root = 'data', \r\n",
    "        year = '2012', \r\n",
    "        image_set = 'train', \r\n",
    "        download = True, \r\n",
    "        transform = None, \r\n",
    "        target_transform = None, \r\n",
    "        transforms = None):\r\n",
    "\r\n",
    "        super().__init__(root, year=year, image_set=image_set, download=download, transform=transform, target_transform=target_transform, transforms=transforms)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        # For now we can discard the annotation/label, we can modify this method later should we need it\r\n",
    "        # Note that the variable length of the annotations causes problems with the dataloader when retrieving\r\n",
    "        # a batch\r\n",
    "        target, label = super().__getitem__(index)\r\n",
    "\r\n",
    "        lab_image = self.preprocess_image(target) # target is the original PIL RGB Image\r\n",
    "\r\n",
    "        return lab_image, transforms.ToTensor()(target) # Convert PIL Image to Tensor to use a dataloader\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    Takes a PIL Image in RGB mode and transfers it to CIELab color space.\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    def preprocess_image(self, img):\r\n",
    "        #resize_transform = transforms.Resize((NET_IMG_SIZE, NET_IMG_SIZE))\r\n",
    "\r\n",
    "        #img = resize_transform(img)\r\n",
    "        img = np.array(img)\r\n",
    "        img_lab = rgb2lab(img).astype(\"float32\") # Convert RGB to Lab color space\r\n",
    "        img_lab = transforms.ToTensor()(img_lab)\r\n",
    "\r\n",
    "        # Adjust all channels to range [-1,1]\r\n",
    "        img_lab[[0], ...] = img_lab[[0], ...] / 50. - 1. # L\r\n",
    "        img_lab[[1,2], ...] = img_lab[[1,2], ...] / 110. # ab\r\n",
    "\r\n",
    "        return img_lab\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Download the Pascal VOC2012 datasets\r\n",
    "# For now, we'll use the 'train' image subset as training data and 'val' as the testing set.\r\n",
    "training_data = VOCColorization(\r\n",
    "    'data', \r\n",
    "    year='2012', \r\n",
    "    image_set='train',\r\n",
    "    transform=transforms.Resize((NET_IMG_SIZE, NET_IMG_SIZE)), \r\n",
    "    download=True)\r\n",
    "\r\n",
    "test_data = VOCColorization(\r\n",
    "    'data', \r\n",
    "    year='2012', \r\n",
    "    image_set='val',\r\n",
    "    transform=transforms.Resize((NET_IMG_SIZE, NET_IMG_SIZE)),\r\n",
    "    download=True)\r\n",
    "\r\n",
    "print(f'Training dataset size = {len(training_data)}')\r\n",
    "print(f'Testing dataset size = {len(test_data)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using downloaded and verified file: data\\VOCtrainval_11-May-2012.tar\n",
      "Extracting data\\VOCtrainval_11-May-2012.tar to data\n",
      "Using downloaded and verified file: data\\VOCtrainval_11-May-2012.tar\n",
      "Extracting data\\VOCtrainval_11-May-2012.tar to data\n",
      "Training dataset size = 5717\n",
      "Testing dataset size = 5823\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Sample code to visualize random Colorization dataset images\r\n",
    "lab_img, rgb_img = training_data[random.randint(0, len(training_data))]\r\n",
    "print(f'lab_img = {lab_img.shape}\\nrgb_img={rgb_img.shape}')\r\n",
    "\r\n",
    "# Slice off L and ab channels\r\n",
    "L = lab_img[[0], ...]\r\n",
    "ab = lab_img[[1,2], ...]\r\n",
    "\r\n",
    "# Convert from 1xHxW array to HxW so we can display it with PyPlot\r\n",
    "new_L = L[0, :, :]\r\n",
    "print(new_L)\r\n",
    "\r\n",
    "# Display our images using pyplot\r\n",
    "rows, cols = 1, 2\r\n",
    "fig = plt.figure(figsize=(12,12))\r\n",
    "\r\n",
    "fig.add_subplot(rows, cols, 1)\r\n",
    "plt.title(f'Original (Resized to {NET_IMG_SIZE}x{NET_IMG_SIZE})')\r\n",
    "plt.axis(\"off\")\r\n",
    "plt.imshow(transforms.ToPILImage()(rgb_img))\r\n",
    "\r\n",
    "fig.add_subplot(rows, cols, 2)\r\n",
    "plt.title('L* Channel')\r\n",
    "plt.axis(\"off\")\r\n",
    "plt.imshow(new_L, cmap='gray')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create dataloaders for our datasets\r\n",
    "training_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\r\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#lab_img, rgb_img = next(iter(training_dataloader))\r\n",
    "\r\n",
    "#print(f'lab_img.shape = {lab_img.shape}\\nrgb_img.shape = {rgb_img.shape}')\r\n",
    "#print(f'lab_img = {lab_img}\\n')\r\n",
    "#print(f'rgb_img = {rgb_img}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "body = create_body(resnet18, pretrained=True, n_in=1, cut=-2)\r\n",
    "model = DynamicUnet(body, n_out=2, img_size=(NET_IMG_SIZE, NET_IMG_SIZE))\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "print(f'Using device: {device}')\r\n",
    "\r\n",
    "print(model)\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\davva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n",
      "DynamicUnet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Sequential(\n",
      "      (0): ConvLayer(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): ConvLayer(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (4): UnetBlock(\n",
      "      (shuf): PixelShuffle_ICNR(\n",
      "        (0): ConvLayer(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): ConvLayer(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): UnetBlock(\n",
      "      (shuf): PixelShuffle_ICNR(\n",
      "        (0): ConvLayer(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): ConvLayer(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): UnetBlock(\n",
      "      (shuf): PixelShuffle_ICNR(\n",
      "        (0): ConvLayer(\n",
      "          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): ConvLayer(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): UnetBlock(\n",
      "      (shuf): PixelShuffle_ICNR(\n",
      "        (0): ConvLayer(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): ConvLayer(\n",
      "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): PixelShuffle_ICNR(\n",
      "      (0): ConvLayer(\n",
      "        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "    (9): ResizeToOrig()\n",
      "    (10): MergeLayer()\n",
      "    (11): ResBlock(\n",
      "      (convpath): Sequential(\n",
      "        (0): ConvLayer(\n",
      "          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (1): ConvLayer(\n",
      "          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (idpath): Sequential()\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): ConvLayer(\n",
      "      (0): Conv2d(97, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (13): ToTensorBase(tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DynamicUnet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): PixelShuffle_ICNR(\n",
       "      (0): ConvLayer(\n",
       "        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (9): ResizeToOrig()\n",
       "    (10): MergeLayer()\n",
       "    (11): ResBlock(\n",
       "      (convpath): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ConvLayer(\n",
       "      (0): Conv2d(97, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (13): ToTensorBase(tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test to ensure that our model accepts inputs and returns outputs of the correct shape\r\n",
    "lab_img, rgb_img = next(iter(training_dataloader))\r\n",
    "\r\n",
    "L_channel = lab_img[:,[0], ...]\r\n",
    "ab_channels = lab_img[:,[1,2], ...]\r\n",
    "\r\n",
    "print(f'L_channel.shape = {L_channel.shape}\\n')\r\n",
    "print(f'ab_channel.shape = {ab_channels.shape}\\n')\r\n",
    "\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    L_channel = L_channel.to(device)\r\n",
    "\r\n",
    "    ab_hat = model(L_channel)\r\n",
    "\r\n",
    "    print(f'ab_hat = {ab_hat.shape}')\r\n",
    "\r\n",
    "    colorized_img = rgbfromlab(L_channel, ab_hat)\r\n",
    "\r\n",
    "    #pil_img = transforms.ToPILImage()(colorized_img[0])\r\n",
    "\r\n",
    "    plt.imshow(colorized_img[0])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Train a Unet (ResNet18 backbone) with L2 Loss\r\n",
    "# Define optimizer and loss function\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
    "loss_func = nn.MSELoss()\r\n",
    "\r\n",
    "# Define training loop step and training Engine\r\n",
    "def train_step(engine, batch):\r\n",
    "    model.train()\r\n",
    "    optimizer.zero_grad()\r\n",
    "    lab_img, rgb_img = batch[0].to(device), batch[1]\r\n",
    "\r\n",
    "    L_channel = lab_img[:,[0], ...]\r\n",
    "    ab_channels = lab_img[:,[1,2], ...]\r\n",
    "\r\n",
    "    ab_prediction = model(L_channel)\r\n",
    "\r\n",
    "    #print(f'L_channel.shape = {L_channel.shape}\\tab_channels.shape = {ab_channels.shape}\\tab_pred.shape = {ab_prediction.shape}\\n')\r\n",
    "\r\n",
    "    loss = loss_func(ab_prediction, ab_channels)\r\n",
    "    loss.backward()\r\n",
    "\r\n",
    "    optimizer.step()\r\n",
    "    \r\n",
    "    return loss.item()\r\n",
    "\r\n",
    "trainer = Engine(train_step)\r\n",
    "\r\n",
    "# Define validation loop step and validation Engine\r\n",
    "def validation_step(engine, batch):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        lab_img, rgb_img = batch[0].to(device), batch[1]\r\n",
    "\r\n",
    "        L_channel = lab_img[:,[0], ...]\r\n",
    "        ab_channels = lab_img[:,[1,2], ...]\r\n",
    "\r\n",
    "        ab_prediction = model(L_channel)\r\n",
    "\r\n",
    "        return ab_prediction, ab_channels\r\n",
    "\r\n",
    "evaluator = Engine(validation_step)\r\n",
    "\r\n",
    "# Define and attach metrics to engines\r\n",
    "#accuracy = Accuracy()\r\n",
    "#l2_loss = Loss(loss_func)\r\n",
    "\r\n",
    "#accuracy.attach(trainer, \"accuracy\")\r\n",
    "#l2_loss.attach(trainer, \"l2_loss\")\r\n",
    "\r\n",
    "#accuracy.attach(evaluator, \"accuracy\")\r\n",
    "#l2_loss.attach(evaluator, \"l2_loss\")\r\n",
    "\r\n",
    "# Add event handlers to trainer engine\r\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=10))\r\n",
    "def log_training_loss(engine):\r\n",
    "    print(f\"Epoch[{engine.state.epoch}] Iter[{engine.state.iteration}] Loss: {engine.state.output:.5f}\")\r\n",
    "\r\n",
    "#@trainer.on(Events.EPOCH_COMPLETED)\r\n",
    "#def log_training_results(engine):\r\n",
    " #   engine.run(training_dataloader)\r\n",
    "  #  metrics = engine.state.metrics\r\n",
    "   # print(f\"Training Results - Epoch: {engine.state.epoch} Avg loss: {metrics['l2_loss']:.2f}\")\r\n",
    "\r\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\r\n",
    "def log_validation_results(engine):\r\n",
    "    evaluator.run(test_dataloader)\r\n",
    "    metrics = evaluator.state.metrics\r\n",
    "    print(f\"Validation Results - Epoch: {evaluator.state.epoch} Avg loss: {evaluator.state.output:.5f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer.run(training_dataloader, max_epochs=3)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "dfa02dee088c29a9ad5235ddd12ddae865f14210b2ad5609320376f4ee592e8c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}